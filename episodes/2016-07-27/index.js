export default {
  title: `Getting started with web audio`,
  guests: [
    {
      name: 'Chris Lowis',
      twitter: 'chrislowis',
      links: [
        `[Web Audio Weekly](http://chrislowis.co.uk/waw.html)`,
        `[Web Audio API @ MDN](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)`,
        `[Web Audio Slack Channel](https://web-audio-slackin.herokuapp.com/)`,
      ],
      tips: [
        `[Canopy](http://hoch.github.io/canopy/) is a Web Audio scratch pad / visualisation / debugging tool`,
        `[Web Audio Dev Tools in Firefox](https://hacks.mozilla.org/2014/06/introducing-the-web-audio-editor-in-firefox-developer-tools/)`,
        `[Web Audio School](http://mmckegg.github.io/web-audio-school/)`,
      ],
      picks: [
        `[Lost Art Press](https://lostartpress.com/)`,
      ],
    },
    {
      name: 'Alejandro Mantecon Guillen',
      twitter: 'alemangui',
      links: [
        `[Recreating the BBC's sounds of the radiophonic workshop](http://webaudio.prototyping.bbc.co.uk/)`,
        `[Pizzicato library](https://github.com/alemangui/pizzicato)`,
        `[Web audio resources](https://github.com/alemangui/web-audio-resources)`,
      ],
      tips: [
        `When you dive into new realms of programming, be it web-audio, functional programming, or whatever it is you're after, don't be afraid to dive in and iterate. Start with simple micro-projects and keep growing a notch every time. I find it hard to really get into new technology without getting my hands dirty from the start. Practice is essential.`,
      ],
      picks: [
        `[Chrome's musiclab](https://musiclab.chromeexperiments.com/)`,
      ],
    },
  ],
  description: `
    Web audio opens the door for rich multimedia, audio and gaming applications. It remains an unknown topic for many. Let's get an overview at audio programming with JavaScript and an introduction to some tools and frameworks that can make your life easier doing this.
  `,
  youTubeId: 'sucLfBy-dVY',
  podbeanId: 'beruc-614d9c',
  shortUrl: 'http://jsair.io/audio',
  host: {
    tips: [
      `Make a chrome extension to make the tweet sound effect I was talking about :)`,
      `Check out [Tero Parviainen](https://twitter.com/teropa)â€™s talk at [ng-europe](https://ngeurope.org/#speakers) and at [ng-conf](https://www.youtube.com/watch?v=vsl5O4ps7LE)`,
    ],
    picks: [
      `[p-s](https://npmjs.com/package/p-s) All the benefits of npm scripts without the cost of a bloated package.json and limits of json`,
    ],
  },
  transcription: `
    KENT: We're live with JavaScript Air. Hello, everyone! My name is Kent C. Dodds and I am your host for JavaScript Air. This JavaScript broadcast podcast that is awesome. So today, we're gonna be talking about getting started with web audio. This is episode 33. So before we get into our subject with our subject matter experts, I'd like to give a shout out to our sponsors that make many of the cool things about the show possible.

    So first, Egghead.io, the show's premiere sponsor, has a huge library of bite-sized web development training videos. Check them out for content on JavaScript, Angular, React, Node, and more. And Egghead.io is the host of two free courses from Dan Abramov. Find them at Egghead.io/redux

    And Front End Masters is a recorded expert-led workshop with courses on Advanced JavaScript, Asynchronous, and Functional JS, as well as lots of other great courses on front end topics. And web pack and open source workshops coming up next month from yours truly. I've spent countless hours and lost so much sleep, so I'd love for you to show up.

    And then TrackJS reports bugs in your JavaScript before customers notice them, and with their telemetry timeline, you'll have the context to actually fix them. Check them out and start tracking JavaScript errors today at trackjs.com.

    And WebStorm is a powerful JavaScript IDE. It makes developers more productive with its super intelligent assistance for JavaScript, Node, Angular and React, and integration with different tools. Learn more at jetbrains.com/webstorm.

    And finally, Trading Technologies is looking for passionate and inventive full-stack JavaScript developers who want to work on cutting edge solutions in a collaborative and challenging environment. Go help them build the top choice platform for derivative traders.

    All right, sweet, so because this is a live show, we can interact with you, our audience, and so if you have any questions, feel free to yield to them on Twitter with the hashtag #JSAirQuestion. And I've got it open right here. I will monitor that, and we will get your questions answered toward the end of the show. And then also remember that this is indeed a weekly show, so next week we're going to be talking about typed functional programming in JavaScript. This is gonna be an awesome show. We'll have Phil Freeman, Jordan Walke, Richard Feldman, and Alfonso Garcia-Caro. I'm pretty sure that's how you say his last name. Really, really awesome developers from various communities, PureScript, Ohm, React, and recently (mumbles). And so yeah, it's gonna be a fantastic episode. I recommend you check it out. Same time, same place next week.

    All right, so let's go ahead and introduce everybody. So like I said, I'm your host, Kent C. Dodds, and with us today for our guests we have Chris Lowis.

    CHRIS: Hi everyone!

    KENT: And Alejandro. I can't pronounce the rest of your name, Alejandro. (laughs)

    ALEJANDRO: (laughs) Alex is okay as well. Hello everybody.

    KENT: You go by Alex?

    ALEJANDRO: Alex or Alejandro. Some people struggle. (laughs)

    KENT: I'm pretty sure I can say Alejandro. Do you want to (mumbles) so people know who you are?

    ALEJANDRO: I'm sorry?

    KENT: Do you wanna say your full name?

    ALEJANDRO: Yeah, sure, it's Alejandro Mantecon Guillen.

    KENT: All right, awesome. (laughs) Okay great, let's go ahead and get an intro to each of you. I'd like to get to know who you are and where you work, and what interest you have in the Web Audio API. So we'll go ahead and start with Chris.

    CHRIS: Yeah, hi there. My name is Chris Lowis. I actually work an education technology startup in the UK called FutureLearn, but my interest in web audio, it predates me working here. I was a research engineer at the BBC and BBC's R&D and that's when I started working with the Web Audio API very early on. And was a founding member of the W3C group that has gone ahead and is standardizing the Web Audio API so that it works in all the browsers. And so I coach at the working group at W3C for a while. And then since I've left the BBC, I left that responsibility but I've carried on doing things with web audio for fun, including my newsletter, Web Audio Weekly, which is a source of news and links about web audio, which I send out probably not weekly, monthly if you're lucky, but it comes out when I've got things to say. (laughs)

    KENT: Great, yeah. Sounds like something people should subscribe to. Thank you for your work on the web audio spec, that's great. Standardizing that is a good thing. Alejandro, let's hear from you.

    ALEJANDRO: Yes, I am a web and mobile developer. I professionally don't do anything linked to web audio, but I've always been interested in music. And since I was young, I jumped around with my friends, I always tried to experiment with sounds, et cetera, and I'm also pretty passionate about programming, so the Web Audio API became the perfect mix of my interests. And I've been playing around with web audio for some time now. I created a small library called Pizzicato JS, which is in GitHub, as well as a few projects that you can find there as well. And I can confirm the Web Audio Weekly by Chris is a fantastic resource, which I am subscribed, and you should absolutely subscribe as well.

    KENT: Awesome, great. Let's make sure we get links to all these things that you mentioned in the links section for the show notes. Sweet! So I think a good way to kick off our conversation is about forming a baseline so everybody knows what we're talking about here. So can we get a general idea, conceptually, of what the Web Audio API is?

    CHRIS: I can have a go, Kent. So the Web Audio API is a way of working with sound in the browser and in web applications. I guess many of you, many of the viewers here today or listeners today will maybe be familiar with things like the HTML audio tag, which allows you to insert a piece of audio to play within a HTML document. But if you want more granular control over that audio, you want to start it and stop it at a precise time, you want to change the volume of it smoothly over time based on a user's interactions, those kinds of things have always been quite difficult to do with things like the audio tag and the Web Audio API lets you do that fundamentally. So for building any kind of application that needs to work with audio, the Web Audio API is the API to use.

    KENT: Interesting. Can you talk about some of the things that are possible with the HTML5 audio element?

    CHRIS: So one of the things that's, what's possible with it, the audio element, is it will decode audio for you. So you can decode MP3 and all the kinds of formats that your browsers support and it will allow you to play it and start it and stop it. You can do some simple automation, like change the volume over time using hooks into the regular kind of DOM hooks into the audio script to do that. But one of the things that you might struggle with, for example, if you're building a game in your browser and you want to have the audio synchronized very accurately with what's happening on screen, so maybe your character, something in the game explodes and you want an explosion sound, if you just try and start, load an audio tag in the background and play the explosion sound, you will find that it doesn't synchronize very well with what's happening on the screen. And that's because everything in the control environment there is happening in JavaScript's main thread, and you can't guarantee when things will execute.

    And so fundamentally, what the Web Audio API lets you do is take all of that kind of audio processing out of the main thread and process it in somewhere that the browser gives high priority to so that thing will happen when you say that will happen, so you can schedule things in advance. And so it's, yeah. The audio API is fine for its purpose, which is just embedding audio files in documents.

    ALEJANDRO: Yeah, and actually talking about games, (mumbles) other than precision which is clearly a huge advantage. It's also the filtering and effects. Sometimes the same audio that you have can be in the context of the character being inside a cave, for example, so the reverb that you can listen, you can do this kind of addition of the audio directly in Web Audio or if your character is talking through a phone or behind a wall, all of these things can be done without having to download a separate audio file and just by editing the one that you have.

    KENT: Cool, okay. We've talked about games, I think that's an obvious use case for Web Audio API, like you want to have sound effects and stuff as you described, but are there any other use cases? Like, would I ever want to use the Web Audio API if I wasn't building a game?

    ALEJANDRO: Yeah, yeah, for sure. Overall, (mumbles) mainstream apps, sometimes there's a bit of sound response to user interaction and user experience, like clicking on a button doing the click sound or applications such as Skype or Google Hangouts that have these very characteristic sounds. But beyond that, and I think one of the things I'm more excited about is applications about music creation and audio creation. Up until recently, there's huge applications that are (mumbles) based like GarageBand and Logic and stuff like that that lets you create audio and create music and create multimedia experiences, but they're pretty huge applications that are separate. And the fact that we have now the tools to create this inside the browser, it's quite mind blowing to me for two reasons. The first is that it opens very important tools to a lot more people, so the web is accessible to a huge number of people, and almost everybody will have a full-fledged audio programming environment directly in their browser just by opening the console, so that's incredible. And the other one is that it doesn't live in isolation because in the browser, we also have other APIs that are wonderful to make 3D, (mumbles) to make connections between computers, et cetera. So it not only catches up to the level of potential that desktop applications have, in my opinion, it completely surpasses it is because it builds upon a lot more tools. So there's definitely a big area for music creation and audio editing software that we're gonna hopefully see coming up in the next years.

    KENT: Really interesting. So would you suggest that maybe we're not leveraging the Web Audio API on the web as much as we should? Should more apps be leveraging the Web Audio API? Are there interactions that you experience and you're like, "Oh, audio would really enhance this experience?"

    ALEJANDRO: Yes (laughs). I'm not a professional musician at all, but I like to play around with instruments, and for instance, not so long ago, I plugged my guitar into the computer and I started taking that input with Web Audio and actually started to create effects and layers and this and that. And there are some projects today of guitarist stomp boxes and guitar effects that can be used, and this is just super super fun, and there's a lot more of that kind of thing that could be done.

    CHRIS: And I would also add to that. I think one of the things that we're just starting to really get ready for with Web Audio is the fact that it does now work in a lot of different browsers. And so I think it's fair to say that the kinds of applications that people have built up to now have kind of been built by early adopters, so people who are really excited about this technology, people who probably have quite a good understanding of how to do audio manipulation anyway in environments like what Alejandro mentioned. But now that we see the cross browser compatibility, so Web Audio is now working pretty, pretty consistently in Firefox, Chrome, and Internet Explorer Edge. It works pretty well in Safari. They tend to lag a little bit behind with things, but it works well in Webkit based browsers. And it works well in mobile, too. We're then seeing that people who would maybe like to use audio for audio icons, for accessibility, for enhancing regular documents to explain concepts a little bit better, that they're now able to start doing that. And it feels like it's the right time. So probably the kinds of applications that you might think to build in a Web Audio API, don't base them just on the demos available today. We're gonna see a lot of things that come along in the pipeline that touch on a lot of different areas, I think.

    KENT: Okay, yeah, that makes sense. I'm wondering if maybe, would you see a future where all apps have some sort of effect? Right now, if I have on the desktop, sometimes I'll press a button and it will make a little sound effect, like Skype comes to mind. They do all kinds of crazy things. But we don't have that same kind of experience normally on web. So do you see a future where I'm on Twitter and I send a tweet and it plays a little "bloop!" or something like that? Is that what you're describing?

    CHRIS: That's it, I think so. As someone who's been programming on the web for a long time, I can remember the dark days of auto playing MIDI files when you went to websites and things that would just auto play. And I think somehow auto playing music or sounds that play without user interaction have got a really rap on the web, and people tend to stay away from them. But like you say, we hear these things all the time now. We're used to our devices giving those tactile and auditory feedback in terms of the actions that we perform. And so I think people are starting to rediscover that. And that the nice little sound icons and those kind of things are starting to make their way into the web as well, I think.

    KENT: I like that term, "sound icons." Yeah, yeah, I like that. So actually just kind of tangential, but a little bit curious. I know when I'm playing a YouTube video or if I'm on Pandora or Google Music or something, at least in Chrome, and I think Firefox has this, but there's a little audio or a speaker symbol that pops up in my tab, and it's really nice so I know where the music is coming from. Does that same speaker icon come up when something is using the Web Audio API?

    ALEJANDRO: Yeah, anytime there's sounding popping up, you will see it. So normally you shouldn't have any rogue tab doing stuff that it shouldn't. Of course, you're talking about these mainstream applications, and I also agree with Chris that most of the applications that are now out there for Web Audio were made by early adopters, but I am quite surprised at the amount of art/multimedia projects that have emerged out of this. They are pretty mind-blowing. I've seen audio visualizations that are insane, and 3D spatialization of audio (mumbles), because also, with Web Audio coming back to games a little bit, you can also spatialize your audio files on your audio stream. So if you're passing through with a car, you'd hear the Doppler effect without having to re-download another file. But this, I think there's a new, it's really not new because (mumbles) all the time, but like a re-emergence of art and multimedia projects that are done just for fun, I guess, that are also quite nice to see around.

    KENT: I'm not sure why, but I had this crazy in my head about a fun application that could use the Web Audio API. So it's like a progressive web app right on your phone, and it's like PokÃ‡mon Go except for music, and so you get closer and closer to this spot and it starts playing the song coming from that spot. That sounds like a fun little app to build. (laughs)

    ALEJANDRO: Absolutely. (laughs)

    CHRIS: There's actually been a couple of interesting applications or games made for blind players, and so there was one that was demoed, I think last year, which was kind of a pong game but where instead of seeing where the bat and the ball were, you could hear them within the virtual environment. And there's been some interesting games around navigating a maze but in the dark and just using your ears and spatialization for that. And I think that's quite exciting.

    KENT: Yeah, I think when you combine technologies is when things get interesting. So let's combine Web Audio and canvas to make a really cool visualization or a little combined Web Audio with geolocation to do like PokÃ‡mon Go for audio, whatever. I think that's where things kind of get really interesting. As you were talking about, lots of the demos to date are very much like, let's have a couple knobs that you can mess around with and make a really sharp sound or make a really high pitch noise or whatever. But actually combining technologies to make really interesting experiences I think is a future I'm looking forward to.

    CHRIS: Yeah. I think one of the challenges here is, although the language that you program the Web Audio API in JavaScript is kind of familiar to a lot of (mumbles) people come to it, suddenly into the world of Web Audio and they're confronted by a lot of unfamiliar concepts, and once that... I mean, I can trace the history of the Web Audio API as it currently exists back to a language that was developed by Bell Labs and in Stanford in the late 1950s by Max Matthews and John Channings developed it, and these are kind of languages that were the very, very first, some of the very first programs that ran on computers what to do with music. And there's actually from some very strong similarities between how those languages worked in the '60s on mainframe computers and how the Web Audio works today. This idea of connecting building blocks together that process your sound using a graph, that concept fundamentally hasn't changed in 50 years of computer music. And it's embedded in how the Web Audio works, API works, and so when people come to it who are new, they have quite a lot of new terminology and concepts to learn even though they're working in a familiar environment. And I think in many ways there's parallels with that. And something like WebGL, you can't just dive into doing 3D graphics unless you have some knowledge of that space, as well, I think.

    ALEJANDRO: Yeah, I think I can identify with what Chris just said. I didn't have the background, and for me at the beginning it was kind of challenging, which is also why I created pizzicato because I found myself abstracting code more and more and more often, and it just took the shape of a library. But something that caught my attention was a comparison made with the (mumbles) workshop at the BBC in the early '60s, where they basically created the effects for TV shows and radio shows like Doctor Who and stuff like that. And from what I understand, they plugged audio sources, like a guy speaking in a microphone or an oscillator generating a signal. And they plugged it in several devices that would somehow edit or alter this signal. So maybe they would pump up the gain, maybe they would split the signal in two parts. There were even physical nodes, you would say, that were to get some reverb or some echo, etc. And after these engineers created this graph, there was an output of the graph which was the sound that they were looking for. It's super interesting that, like you said, it still works like this today. So we have an audio context object which represents our audio workshop, where we can create nodes which generate sound or edit sound or can analyze sound. And we create this graph that can be as intricate as you want, and at the end, you have this output of the audio graph that you just plug into the context destination and you can hear it in your computer. And something that fascinated me is that the BBC, which of course is pioneering everything there is to audio, including Web Audio, has a site in which they recreate these '60s sounds, like the voice of Delex in Doctor Who and stuff like that. These physical analogue graphs, they recreate them with Web Audio. And for me that's fantastic as a learning tool. And it was super good.

    KENT: So actually what you described is really interesting to me. It seems like the Web Audio API could be very similar to what you were talking about, where you have all these boxes that things would come into and then it would go out and have reverb and stuff. That sounds very much to me like a stateless function in JavaScript. So is the Web Audio API, is that like... we haven't really talked about the API itself and how it works, but do you see a lot of functional programming paradigms coming out of working with the Web Audio API? Or is that space yet to be explored?

    CHRIS: I think the concept of the Web Audio API is very much based on a stream of samples, a stream of digitized music that you apply some function to, use some modification, like a volume change or add some reverb or delay it by a certain amount and then combine it together. And in that way, I think you can think of these building blocks as being pure functions in that they're taking audio and passing it on to the next one. But the way that you program the Web Audio API in the browser is kind of... all of those operations are very expensive for a computer to do, and they're still very expensive in most normal applications, like useful applications. And so the Web Audio API kind of abstracts that away so that your browser can implement it and the browser engine is doing that hard work for you and you're concerned about plugging it together.

    So I think rather than thinking of it in terms of functional programming, I think it's more like a declarative language. It's you're telling the browser how you want to connect these building blocks together, and you're letting the browser itself figure out the best way of manipulating the samples and the memory in order to achieve that effect. But the Web Audio API, it's not yet reached a kind of... it's not fixed. It's an evolving standard like most things are on the web now. And so in the last year, we've seen quite a lot of people making suggestions and changes to make the API more like a modern JavaScript API. So most of the things that do asynchronous operations like decoding of sound or loading samples, they do that using promises and those kinds of things.

    KENT: Interesting. Yeah that makes me think. I actually just tried to Google for RxJS Web Audio, and I couldn't find anything, which is too bad. But it sounds like when you said, "stream" like these are streams of audio, that totally in my mind is like, "Okay, RxJS." I feel like that would be a pretty interesting mesh of technologies. And so if anybody out there likes observables, I'd be really interested to see a solution that combines observables with Web Audio.

    So earlier, Chris, you were talking about, even experienced JavaScript developers come into the Web Audio API, and they're bombarded with a lot of new terminology and stuff, even back from the original concept in the '50s. So what are some of the confusing parts of the Web Audio API you're talking about, and the Web Audio or just audio concepts? And how would you recommend people getting into Web Audio get over these problems?

    CHRIS: I think I would just try and dig up the link as it occurred to me about this. So there's a really good, and I'll add it to the notes, but there's a really good guided sequence of lessons that take you through, within the browser you can, you have a little puzzle of (mumbles) to make this particular sound, and you can hear what it's supposed to sound like, and then you write a code on it and check it against what it's supposed to sound like. And it guides you through a lot of the concept of Web Audio API. And if I'm running tutorials and workshops to teach people, that tends to be widely used. I think that's a really nice way of doing it. So I think that's good way of learning the concepts and how they work. I think the Mozilla MDN site, so the documentation that's written is probably the best out there. And it's very comprehensive and it's also has a lot of narrative documentation in the examples and those kinds of things.

    The API has changed quite a bit in the last, because it's a moving target, but those implementations have been in the wild for several years now. But they have changed, and so when you Google and find tutorials and so on, you sometimes find there's some differences between what's in those and what actually works now. Although, given that isn't a set in stone standard, I think the editors do a really good job of trying to keep backwards compatibility as well. But yeah, those two places. I'll dig out the interactive tutorial. I think that's fantastic. But also the barrier to entry is really low. I mean you do open the console and with a few lines, you can start making a horrible noise that you don't know how to stop quite quickly. (laughs)

    KENT: (laughs) Nice.

    ALEJANDRO: Yes, and that is right, actually. I think that there is a lot of learning curve related to audio engineering itself, but it's also slightly unintuitive at first for JavaScript developers in the sense that, for instance a couple of things that happened to me at the beginning is that I created an oscillator, which was fantastic. I'd have my oscillator with the sine wave. I hit Play with the oscillator. I heard the horrible noise that I wanted to stop immediately, which I did. And when trying to restart the oscillator, I found out that it was dead. The way you do it is that oscillators are meant to be single lived. And you play it once, you stop it, they're dead, they're zombie, you disconnect them and you throw 'em away. And if you want to play again the same piano note, you have to recreate another oscillator, bring it back, connect it, and (mumbles). So in the beginning, that seemed super wasteful for me, but it isn't. And the browser is something nice for these kind of operations, but it's just not very intuitive.

    Or for instance, I was also a bit puzzled at first why functions that take parameters through a curve, for example, if I have a sound and I want to put the volume of this sound to one in two seconds, they never have callbacks. Their timing was a bit different because as you know, set timeout in JavaScript is not super mega precise, and it can vary depending on how the browser is busy or not, et cetera. So trying to pair the audio context timing with image after timing, et cetera. So it took a bit of getting things together and getting used to programming in a certain way, that I think went even beyond the concepts of just audio engineering. But yeah, for sure. Educationally, the entry barrier is super low, so it's just a bit of awkwardness at first, but then you can definitely get around.

    KENT: Oh, did you have something to say, Chris?

    CHRIS: No, I was just gonna reiterate what Alex said. The real challenge of dealing with these three separate clocks in a lot of applications where you've got the timer that we're used to, with set timeout and those kind of things, that's what's monitoring your user interface, you may have an animation timer for some of the things that are happening, and then you've got this audio timer as well, and you have to synchronize between them. It's easy to make mistakes there that will cause your audio to glitch, yeah. And so keeping an eye out for that, if you're getting glitching audio with things that you don't think are particularly complicated, then having a look. Chris Wilson's article which he wrote, which is called for HTML5 Rocks, I think it's called A Tale of Two Clocks, does a really good job of explaining that fundamental concept when you start playing with Web Audio.

    KENT: Awesome. Are there other fundamental concepts about audio in general, like you were talking about from the original language from the '50s? Any other concepts that might trip up beginners?

    CHRIS: An audio processing concept that's baked into the Web Audio is this difference between working with sound in what we call a time domain. So if you imagine that sound is a waveform and we can describe it as a sequence of numbers, then we can process audio by working with that sequence of numbers that just describe the amplitude of the sound wave at a particular point in time. But for a lot of operations in the Web Audio and when you're doing things with audio, it's easier to first transform a sound into a frequency domain. And so you think about maybe a graphic equalizer on your hi-fi or your stereo at home, it's much easier to say, "I want the bass to be a little bit louder and the treble to be a little bit quieter," than it is to think about how you would modify a waveform so that it had less bass and less treble. So sometimes it's easier to transform first into frequency and then work with frequencies. And so those concept come up in the API a little bit, and you think, "Well why in this case frequency and in this case time?" Again, the details of that are abstracted away from you nicely by the API, but it's a concept that's kind of, yeah. As you get more advanced and you're trying to do certain things, it's useful to be familiar with.

    KENT: Yeah, okay. So as I'm getting started in the Web Audio API, my favorite way to learn APIs is to build something. And so what would be the best approach to building things with this API? Should I just look up the resources that you mentioned and start hacking away at stuff? How do I, I don't know. How do I explore this API in a way that I can end up with a reasonable result at the end without getting too frustrated at my lack of experience with it?

    ALEJANDRO: I think, definitely Mozilla's MDN is fantastic and they do a very good job of explaining not only the API itself but the concepts behind it. There's several tutorials out there. The other way also when I was learning, I created a repo called Web Audio Resources in which I have a section of learning. So these are very simple tutorials that helped me get on track. Simple stuff like creating a little keyboard that just plays one note with one oscillator, it's really super enlightening. And from then on, you can start adding effects. You can start adding movement to the sound. But I guess the only thing to be careful of is making sure that the tutorials are updated with the current API, because it has changed a lot. For instance, there's many changes, but the whole script processor I think is set to be deprecated in favor of some sort of web workers approach. There's things like that. So that's the hard part, is that you try to get recent ones, because again, like you say, it's a moving target.

    KENT: So if I was, let's say I am, let's say I work for Twitter and I want to add a sound effect for when I click the tweet button. I want it to go, "Tweet!" or I want it go, "Blop!" or something like that. So for something like that, can I create that entire sound using just the Web Audio API? Or do I need to have a sound file that I manipulate, like an existing stream that I manipulate, to create the sound that I want?

    CHRIS: You can actually go both ways with it. So one approach to that thing, which would be a nice thing to try first, would be to record that sound in some way and then load it up asynchronously in the background when your page is loading, and then you can trigger that sound when you mouse over or something or an action happens. And immediately, you start to see with the benefits of the Web Audio API over some other approaches there, and that you only have to load the sound and decode it once and you can play it multiple times. And you can also overlap it. So if you had lots of things tweeting all over the screen, then those sounds would nicely overlap and blend together in a way that would be quite hard to achieve in other ways.

    But yeah, the Web Audio API also provides you with primitives where you could synthesize that sound yourself. So if it was a sound at a particular pitch and then maybe a little bit of echo on it and a little bit of distortion or something, then you can actually generate that together, and then you don't have to load any files and decode them at all. And your sound there becomes effectively just three or four lines of code, and it will generate the sound. So it keeps your page weight down and keeps the number of requests down. But you would have to experiment a little bit to do that. But once you've got it, then you can do things with that sound that you couldn't do if it all had to be prerecorded, such as moving it in space and stretching it out and slowing it down and speeding it up and all those things.

    KENT: Yeah, interesting. That almost makes me think of the difference between a blog post and a video. With a blog post, you can make changes inside of it. If you're talking about a specific API or something, if the API changes, it's really easy to update your blog post, but with a video, if something changes, you need to make an update, you're probably gonna just have to re-record the whole thing.

    CHRIS: Yeah. Yeah, I think it sometimes reminds a little bit of people who create images or things on the page using pure CSS, and so you have no image that you have to download and you can manipulate those things in order to enlarge and shrink it and move it around and you're just declaring it with code. So you can do that kind of thing with sound using the API.

    KENT: Cool. So what about, we were talking earlier, an explosion in a game, something blows up. Could I create that sound with the Web Audio API? Is it powerful enough and reasonable enough for me to make, what I would think, to be a complex sound, and make it sound realistic?

    CHRIS: Yeah, probably. I mean, effectively there's some kind of underlying physics that's happening when something explodes that you're trying to model and then work out, how would that sound. And so I might start with what's called white noise, which is just a hiss. It's sound of all frequencies. The kind of thing you get when you have a detuned radio. But I might think, "Well if I want an explosion, I probably want to filter that so I've got a bit more booming bass and a bit less high frequency, and then I might want to echo that around and double it up and put it in a reverber thing so it sounds like boom." There's various approaches that you could do. Something like an explosion is quite tricky, the physics that's involved. But if you're trying to synthesize an instrument like a flute or a clarinet, then the physics is much simpler and you can get something that sounds a little bit convincing quite quickly.

    KENT: So if I were doing that, would you recommend that I try to do that with the Web Audio API, or would you say a prerecorded thing might be a little bit better?

    CHRIS: I think it really depends on your application, it does. One of the nice things about working with prerecorded sounds in Web Audio is that you can index directly into a part of your buffer. So one of the things that you could do is almost like when you use sprite in CSS and you have lots and lots of tiny images but you use CSS to offset them, you can do the same kind of thing with audios. You can just download and decode the file once, and then when you need the explosion, just jump straight into that point and then loop it for a short snippet, for example. Those kinds of things. So you can, depending on what you're trying to do. Obviously, if you need to prerecord everything then you have to do that work outside of the browser. And so that's a different set of tools, and you might be able to find some samples and those kind of things that will get your started.

    ALEJANDRO: Yeah, so I guess audio synthesis is possible in Web Audio to a very large extent. It's tricky not only in Web Audio, in life, synthesis is sort of tricky, but Web Audio is not only audio synthesis. It's loading an external file, like Chris just said, gives you a manipulation that you don't have with the audio (mumbles) but you do have with Web Audio. And it's not only loading and reading and synthesizing, it's also analyzing audio and seeing waveforms and creating visual stuff or pure numeric analysis of the audio. It goes, I think, beyond the pure synthesization of sounds.

    KENT: Cool. So in this Google doc where you also, somebody wrote in here, "Web MIDI." Does anybody wanna talk about Web MIDI? Is it the same or different from Web Audio?

    CHRIS: Go ahead, Alex.

    ALEJANDRO: Okay. The thing, and that's one of the technologies I'm super excited about, because with Web Audio you can create, kind of instruments, really, that you can synthesize sounds and create custom sounds and instruments. And it is super fun. But the reality is that the computer peripherals are not super good for audio interfacing. I mean, of course you can play a little piano with your computer keyboard when you're mouse clicking on the keys. But it's not meant for it. And you lose some parameters, like the force with which you're hitting the key and stuff like. And MIDI is basically an interface, a standard for musical devices. And it's been around since early '80s I think, and that means that it has many, many years that music manufacturers that have their business in music instruments have created things to play music with, but we can now pull up all this information in Chrome.

    And for instance, I pulled up an old little keyboard that I have here. So this is a full-sized keyboard that is purely MIDI, and they also have a little electric drum set. So all of these things, I can just take the data with my browser, which is insane. And it's also a very simple protocol. So when I hit a piano key or a drum pad, there's a little array with three values, that's it. And the first value tells me what happened, so it was a note on or a note off or something like that, and which channel it happened. The second array is the note, and the third array is the force, I think, or the strength. So, it gives you so much more expression and means to do things. And that combined with Web Audio and with all the other APIs in HTML5 in the browsers, anyways, it's super exciting.

    CHRIS: And I think interestingly with Web MIDI is actually, it's been adopted much more widespread than Web Audio has at this stage. And so I met a friend of mine from Yamaha in Japan a few weeks ago, and just 'round the corner from me here in Camden in London, there's a company called Novation. And both of these companies have just released products that you can buy for several hundred pounds, synthesizers and keyboards. And instead of shipping, which they used to do, shipping a CD-ROM that you would use to configure the device and upload new firmware and modify patches using their computer, they now just tell you to go to a website and connect it. And at the moment they have to say, "Do that in Chrome," but Firefox MIDI implementation is coming really soon, I think, and so then it was (mumbles). But for those manufacturers, this is a really exciting thing for them because they can connect their instruments to the web and allow their users, the musicians, to share patches between each other and build communities around the instruments and so on. It's actually the take up of that has been a lot more rapid and at higher level than I expected. It's really quite exciting.

    KENT: Wow, that's great. Well, I love the web platform. It does the coolest things for our world! It's so awesome. Very cool. We're winding down on our time. And just a reminder to those watching that you can ask questions with the hashtag #jsAirQuestion on Twitter. We do have one that I'm excited to ask, but before we get into those, I just wanna open up the floor for you all to say whatever it is that you'd like to mention that we haven't already covered. (silence) I guess we've covered everything. (laughs)

    CHRIS: We covered quite a lot, yeah. (laughs)

    KENT: All right, cool. Well we'll jump into the Twitter questions. Feel free, anybody watching live, to ask further questions if you have some. So Tero Parviainen, I'm pretty sure, no, I didn't say his name right. I always get it wrong. Sorry, Tero. But the question is, "Do you use any special tooling while developing Web Audio apps? Any tricks to share for inspecting things through DevTools?"

    CHRIS: Yeah, I've got a couple of things that I use frequently. So if you use Firefox, and I think maybe, maybe you have to have the developer edition, but maybe it's in the main line now, there's actually in the developer tools there's a Web Audio developer tool which allows you to inspect the graphs that you've been building and modify them. And so that's very useful. And the Web Audio team in Chrome, Raymond and Hong-Chan, they've built a tool called Canopy, which is a kind of scratch pad in the browser that allows you to visualize what the audio looks like and then change the code and hear it, and it's a very, very useful tool. And that's called Canopy. And I think that's enhanced, that those two told me there's enhanced tools coming into Chrome soon, too, for developer tools. And those things are very useful.

    KENT: Cool. Alejandro, did you have any tips?

    ALEJANDRO: It's basically the same. There's also a third party plugin in Chrome that does the audio graph visualization. But I tried it, it's pretty good. It can get a bit choked up if there's too much. But yeah, those tools are always good. And in general while coding projects, it's also good to have a div with the analyzer to make sure that you see the time domain or the frequency domain of the data you're manipulating to see if the effects are playing correctly and stuff like that. It's a useful tip.

    KENT: Great! All right, I think that, yeah, that we don't have another question from Twitter, so I think let's go ahead and we'll jump into our tips and picks. So I'm gonna go ahead and get started. My tip is, I'm actually looking it up right now, because Tero, the one who asked the question, also tweeted at me earlier during our conversation and he said, "My ng-Europe talk will have RxJS and Web Audio." So it's like exactly what I was thinking, sounds really awesome. And so my tip is to, I'll put this link in the show notes later, but check out his talk when it comes out or watch it live. I imagine ng-europe is gonna be live. And I guess that is coming up October 25th and 26th. Unfortunately, I will be at a different conference at that time, but I'll check it out later. And Tero actually gave a fantastic talk at ng-conf just a couple months ago about visualizations and stuff. It's just really, really cool stuff. I recommend that you check out pretty much everything that Tero does, 'cause he's awesome.

    So my pick is a self-pick. I do these probably every week, actually. I was gonna say occasionally, but let's be honest here. But it's a module that I wrote called PS, P-S. You can find it on npm. But the tagline is, "All the benefits of npm scripts without the cost of a bloated package JSON and limits of JSON." So yeah, basically it's a really nice in-between npm scripts and Gulp. It's really simple. So I recommend you check it out. Sweet. Chris, why don't we have you go next?

    CHRIS: Oh those two sound, (mumbles) sounds great and I'm gonna check those out. So just a couple from me. So very quickly just a little plug for the Slack channel, the Web Audio Slack channel, and that's in the document, too. Very welcoming and friendly group of people over in that Slack channel talking about Web Audio and sharing some ideas. There's a couple of local community groups as well, one in London, one in Berlin, one in Philadelphia. So if people want to organize local meetups, and most of the spec editors and the people who are involved in implementations are there too, so you get quite good information from the horse's mouth.

    And my other pick was not computer related. So when I'm not sat in front of the screen, I enjoy woodworking. I have a small apartment here in London and no room for big, expensive, noisy machines, so I do all my woodwork using traditional methods. And I love the publishing company over in the States called Lost Art Press, who do beautiful books about woodworking to help you learn how to do that and get away from the screen, and yeah. They're a good blend of embracing the digital world but also making paper things that are beautiful and lovely to touch in your house.

    KENT: Great! It's good to have other interests as well and get away from the screen every now and then. Alejandro?

    ALEJANDRO: Thanks, that's super interesting. For me my pick, there is a site called Chrome Music Lab Experiments. And it's super good because they combine, actually, I don't know why I didn't mention this before, but you were asking, "How could I get started with audio terminology and concepts (mumbles)?" I think that is a fantastic place to go because you have these very light, nice, cutesy, very well-designed animations that respond to the concept that they're trying to show in a very graphical way. So you have the concept of harmonics, of oscillators, of chords, everything. So yeah, I spent ages there, just moving around (mumbles) animations and seeing the little oscillators jump. It was just fantastic.

    And for my tip, I guess I was thinking of programming, but it applies to other disciplines, as well, is to get your hands dirty at the beginning. I mean, of course you have to read stuff and investigate, but doing things and iterating in little chunks, I think for me, brings me much more closer to my objectives than pure theory. And it also lets me see the tricky parts quite early. Unless you're doing (mumbles), try to jump in early and make mistakes and iterate. So that's it for me.

    KENT: Cool. I actually had another tip I totally forgot because I was excited to talk about Tero. But my tip is, go out and make a Chrome extension to make that tweet sound effect I was talking about. So if you wanna get into Web Audio, seriously, the best way to learn something is to build something with it and then go out and teach people about it. So for the thing that you build, I would love to get a tweet about a Chrome extension that adds a little, "Bloop!" or a little "Tweet!" every single time I hit the tweet button. That would be cool. I might disable it later because I tweet a lot and that might get annoying, but I don't know. I haven't had this experience before, so yeah, I think that would be cool.

    So let's just wrap things up. So yeah, this has been a great show. Thanks for coming. So just closing announcements. Wanna give a shoutout to our silver sponsors, first ReactJS Program from Tyler McGinnis, Master the ReactJS Ecosystem. They're awesome. Check them out. And Sentry is cross platform crash reporting. So check them out also. I have a couple links here to forms. First is jsair.io/suggest. So if you have a suggestion for a topic or a guest or both, then go to that form, fill it out. I must be honest, I have a very long backlog. People are excited to give me suggestions, and I appreciate that. Please be patient with me while I come up with the time to do all the suggestions. And then feedback, jsair.io/feedback will take you to a feedback form. You can give us feedback on the entire show or specific shows. Really appreciate that feedback. And then jsair.io/email will take you to our email newsletter. I've got to be honest, I'm not 100% certain that that's going to continue forever, so if you want that to continue happening, please let me know in the feedback. So, yeah. Awesome.

    With that, I think I'll just give, oh yeah, a couple other announcements. So next week, we're gonna be talking about functional programming or typed functional programming in JavaScript with Phil Freeman, Jordan Walke, Richard Feldman, and Alfonso Garcia-Caro. It's gonna be a really good show. I'm really excited about this show. So check that out next week. And as always, follow us on Twitter, Facebook, and Google Plus to keep up with the latest. And with that, I think we're all done. So, thank you very much Alejandro and Chris for coming! This has been a great discussion.

    CHRIS: Thanks, Kent.

    ALEJANDRO: Thank you very much.
  `,
}
